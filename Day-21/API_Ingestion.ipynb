{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c79eb9f-7c10-4d69-8837-088d04271177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "bronze_table = \"github_issues_bronze\"\n",
    "per_page = 30\n",
    "token = dbutils.secrets.get(scope=\"my_scope\", key=\"github_token\")\n",
    "\n",
    "def fetch_issues(pages=5):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    all_data = []\n",
    "    for page in range(1, pages + 1):\n",
    "        print(f\"\uD83D\uDD04 Fetching page {page}...\")\n",
    "        res = requests.get(\n",
    "            \"https://api.github.com/repos/apache/spark/issues\",\n",
    "            params={\"state\": \"all\", \"page\": page, \"per_page\": per_page},\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            raise Exception(f\"GitHub API error: {res.status_code} - {res.text}\")\n",
    "        \n",
    "        try:\n",
    "            batch = res.json()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to parse JSON: {e}\")\n",
    "        \n",
    "        if not isinstance(batch, list):\n",
    "            print(f\"Unexpected response structure: {batch}\")\n",
    "            break\n",
    "\n",
    "        all_data.extend(batch)\n",
    "        \n",
    "        if len(batch) < per_page:\n",
    "            print(\"Reached last page.\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Total issues fetched: {len(all_data)}\")\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcff56ce-5647-4e84-b7c2-b7e1d49c7016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading issues updated after: 2000-01-01T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    last_updated = spark.read.table(bronze_table).agg({\"updated_at\": \"max\"}).collect()[0][0]\n",
    "    if last_updated is None:\n",
    "        since_ts = \"2000-01-01T00:00:00Z\"\n",
    "    else:\n",
    "        since_ts = last_updated.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "except:\n",
    "    since_ts = \"2000-01-01T00:00:00Z\"\n",
    "\n",
    "print(f\"Loading issues updated after: {since_ts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445ea5c3-0411-4359-97b8-62b6b689e441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Fetching page 1...\n\uD83D\uDD04 Fetching page 2...\n\uD83D\uDD04 Fetching page 3...\n\uD83D\uDD04 Fetching page 4...\n\uD83D\uDD04 Fetching page 5...\nTotal issues fetched: 150\nIngested 150 new records\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType()),\n",
    "    StructField(\"number\", LongType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"state\", StringType()),\n",
    "    StructField(\"updated_at\", StringType()),\n",
    "    StructField(\"user\", StructType([\n",
    "        StructField(\"login\", StringType())\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Fetch data\n",
    "raw_data = fetch_issues(pages=5)\n",
    "\n",
    "if not raw_data:\n",
    "    print(\"No data fetched\")\n",
    "else:\n",
    "    df = spark.createDataFrame(raw_data, schema)\n",
    "\n",
    "    df_filtered = df \\\n",
    "        .withColumn(\"updated_at\", to_timestamp(\"updated_at\")) \\\n",
    "        .filter(col(\"updated_at\") > lit(since_ts)) \\\n",
    "        .withColumn(\"user_login\", col(\"user.login\")) \\\n",
    "        .drop(\"user\") \\\n",
    "        .withColumn(\"ingest_ts\", current_timestamp())\n",
    "\n",
    "    if df_filtered.count() == 0:\n",
    "        print(\"No new issues to ingest after filtering.\")\n",
    "    else:\n",
    "        df_filtered.write.format(\"delta\").mode(\"append\").saveAsTable(bronze_table)\n",
    "        print(f\"Ingested {df_filtered.count()} new records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ba79d96-9a1a-4818-ac39-89d54b23c750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>number</th><th>title</th><th>state</th><th>updated_at</th><th>user_login</th><th>ingest_ts</th></tr></thead><tbody><tr><td>3199460855</td><td>51364</td><td>[SPARK-52675][ML][CONNECT] Interrupt hanging ML handlers in tests</td><td>open</td><td>2025-07-03T13:44:39.000Z</td><td>WeichenXu123</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198911743</td><td>51361</td><td>[WIP][SPARK-52618][SQL] Casting TIME(n) to TIME(m)</td><td>open</td><td>2025-07-03T13:08:37.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3197564924</td><td>51354</td><td>[SPARK-52660][SQL] Add time type to `CodeGenerator#javaClass`</td><td>closed</td><td>2025-07-03T12:23:07.000Z</td><td>bersprockets</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198964388</td><td>51363</td><td>[SPARK-52673][CONNECT][CLIENT] Add grpc RetryInfo handling to Spark Connect retry policies</td><td>open</td><td>2025-07-03T12:22:06.000Z</td><td>khakhlyuk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198921208</td><td>51362</td><td>[SPARK-52674][SQL] Clean up the usage of deprecated APIs related to `RandomStringUtils`</td><td>open</td><td>2025-07-03T10:49:51.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3161928074</td><td>51227</td><td>[SPARK-52535][SQL] Improve code readability of rule ApplyColumnarRulesAndInsertTransitions</td><td>closed</td><td>2025-07-03T10:33:52.000Z</td><td>zhztheplayer</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198817544</td><td>51360</td><td>[SPARK-52671][SQL] RowEncoder shall not lookup a resolved UDT</td><td>open</td><td>2025-07-03T10:04:31.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198708344</td><td>51359</td><td>[SPARK-52672][SQL] Don't replace Sort/Having expressions with aliases if expression exists in Aggregate</td><td>open</td><td>2025-07-03T09:47:59.000Z</td><td>mihailotim-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187748015</td><td>51323</td><td>[SPARK-52381][CORE][3.5] JsonProtocol: Only accept subclasses of SparkListenerEvent</td><td>closed</td><td>2025-07-03T09:35:46.000Z</td><td>pjfanning</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3197859941</td><td>51355</td><td>[SPARK-52665][BUILD] Fix make-distribution.sh [: missing `]'</td><td>open</td><td>2025-07-03T09:24:50.000Z</td><td>cxzl25</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3196488081</td><td>51351</td><td>[SPARK-52656][SQL] Fix current_time()</td><td>closed</td><td>2025-07-03T09:20:35.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193084236</td><td>51337</td><td>[WIP][SQL][TESTS] Disable stable column aliases in tests if assumed</td><td>open</td><td>2025-07-03T08:55:23.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170102244</td><td>51259</td><td>[SPARK-52561][PYTHON][INFRA] Upgrade the minimum version of Python to 3.10</td><td>open</td><td>2025-07-03T08:44:46.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3176493991</td><td>51280</td><td>[SDP] [SPARK-52576] Drop/recreate on full refresh and MV update</td><td>open</td><td>2025-07-03T08:19:22.000Z</td><td>sryza</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3176799950</td><td>51282</td><td>[SPARK-52575][SQL] Introduce contextIndependentFoldable attribute for Expressions</td><td>open</td><td>2025-07-03T08:09:34.000Z</td><td>gengliangwang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193628652</td><td>51342</td><td>[SPARK-52638][SQL] Allow preserving Hive-style column order to be configurable</td><td>open</td><td>2025-07-03T08:03:32.000Z</td><td>szehon-ho</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198362916</td><td>51357</td><td>[SPARK-52669][PySpark]Improvement PySpark choose pythonExec in cluster yarn client mode</td><td>open</td><td>2025-07-03T07:41:46.000Z</td><td>gwdgithubnom</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3198394330</td><td>51358</td><td>[SPARK-52670][SQL] Make HiveResult work with UserDefinedType#stringifyValue</td><td>open</td><td>2025-07-03T07:39:42.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187248572</td><td>51320</td><td>[SPARK-52613][CORE][SQL] Restore printing full stacktrace when HBase/Hive DelegationTokenProvider hit exception</td><td>closed</td><td>2025-07-03T07:32:19.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193300501</td><td>51339</td><td>[SPARK-52649][SQL] Trim aliases before matching Sort/Having/Filter expressions in `buildAggExprList`</td><td>closed</td><td>2025-07-03T07:28:50.000Z</td><td>mihailotim-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187462351</td><td>51322</td><td>[SPARK-52615][CORE] Replace File.mkdirs with Utils.createDirectory</td><td>closed</td><td>2025-07-03T06:44:57.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3197555691</td><td>51353</td><td>[SPARK-52663][SDP] Introduce name field to pipeline spec</td><td>open</td><td>2025-07-03T06:27:09.000Z</td><td>sryza</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3191401184</td><td>51332</td><td>[SPARK-52632][SQL] Pretty display V2 write plan nodes</td><td>open</td><td>2025-07-03T05:42:08.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3197917883</td><td>51356</td><td>[SPARK-52666][SQL] Map User Defined Type to correct MutableValue in SpecificInternalRow</td><td>open</td><td>2025-07-03T04:02:12.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3162505926</td><td>51230</td><td>[WIP][SPARK-51224][BUILD] Test Maven 4</td><td>open</td><td>2025-07-03T03:53:27.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190819641</td><td>51327</td><td>[SPARK-52630][SS] Reorganize streaming operator and state mgmt code and dirs</td><td>closed</td><td>2025-07-03T03:01:51.000Z</td><td>anishshri-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3195020198</td><td>51348</td><td>[SPARK-52503][SQL][CONNECT][4.0] Fix drop when the input column is not existent</td><td>closed</td><td>2025-07-03T02:41:04.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3195539118</td><td>51349</td><td>[SPARK-52651][SQL] Handle User Defined Type in Nested ColumnVector</td><td>closed</td><td>2025-07-03T01:49:20.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177450990</td><td>51287</td><td>[SPARK-52582][SQL] Improve the memory usage of XML parser</td><td>open</td><td>2025-07-03T00:01:54.000Z</td><td>xiaonanyang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193706249</td><td>51344</td><td>[SPARK-52640][SDP] Propagate Python Source Code Location</td><td>open</td><td>2025-07-02T23:15:21.000Z</td><td>AnishMahto</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3180839163</td><td>51297</td><td>[SPARK-52580][PS] Avoid CAST_INVALID_INPUT of `replace` in ANSI mode</td><td>open</td><td>2025-07-02T22:28:15.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164441897</td><td>51236</td><td>[SPARK-52515][SQL] Add approx_top_k function</td><td>closed</td><td>2025-07-02T22:27:31.000Z</td><td>yhuang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193463767</td><td>51340</td><td>[SS][SPARK-52637] Fix version ID mismatch issue for RocksDB compaction leading to incorrect file mapping</td><td>open</td><td>2025-07-02T22:26:40.000Z</td><td>liviazhu</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190893225</td><td>51331</td><td>[SPARK-52539][CONNECT][FOLLOW-UP] Avoid using TypeAlias that is available from Python 3.10</td><td>closed</td><td>2025-07-02T22:25:54.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3165942571</td><td>51242</td><td>[SPARK-52545][SQL] Standardize double-quote escaping to follow SQL specification</td><td>closed</td><td>2025-07-02T22:24:01.000Z</td><td>dengziming</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3192082330</td><td>51334</td><td>[SPARK-52633][SQL] Deduplicate single `Union` child output before `DeduplicateRelations`</td><td>closed</td><td>2025-07-02T22:21:08.000Z</td><td>mihailotim-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3194809460</td><td>51347</td><td>[SPARK-52023][SQL][3.5] Fix data corruption/segfault returning Option[Product] from udaf</td><td>closed</td><td>2025-07-02T22:18:17.000Z</td><td>eejbyfeldt</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3195805678</td><td>51350</td><td>[SPARK-52652][BUILD] Replace `os-maven-plugin` with `nisse`</td><td>closed</td><td>2025-07-02T21:42:34.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3191593929</td><td>51333</td><td>[SPARK-52634][SQL][DOCS] Update the ANSI compliance page regarding the TIME type</td><td>open</td><td>2025-07-02T17:20:27.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3196566453</td><td>51352</td><td>[SPARK-52409][SDP] Only use PipelineRunEventBuffer in tests</td><td>open</td><td>2025-07-02T17:10:35.000Z</td><td>sryza</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3192826296</td><td>51336</td><td>[SPARK-52635][BUILD][3.5] Upgrade ORC to 1.9.7</td><td>open</td><td>2025-07-02T04:48:26.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187299651</td><td>51321</td><td>[SPARK-52612][INFRA] Add an env `NO_PROVIDED_SPARK_JARS` to control collection behavior of `sbt/package` for `spark-avro.jar` and `spark-protobuf.jar`</td><td>closed</td><td>2025-07-02T04:11:09.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193634752</td><td>51343</td><td>[SPARK-52639][K8S][INFRA][DOCS] Upgrade Volcano to 1.12.1</td><td>closed</td><td>2025-07-02T04:00:35.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3194038302</td><td>51346</td><td>[SPARK-52643][BUILD] Upgrade `extra-enforcer-rules` to support Java 25</td><td>closed</td><td>2025-07-02T04:00:16.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193966871</td><td>51345</td><td>[SPARK-52642][PYTHON] Use daemonWorkers.get(worker) to avoid unexpected out-of-sync between idleWorkers and daemonWorkers</td><td>closed</td><td>2025-07-02T02:34:30.000Z</td><td>ueshin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3161287345</td><td>51225</td><td>[DRAFT][PYTHON] Improve Python UDF Arrow Serializer Performance</td><td>open</td><td>2025-07-01T23:40:05.000Z</td><td>asl3</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190857829</td><td>51329</td><td>[SPARK-52551][SQL][FOLLOW-UP] Enable ANSI mode in PushablePredicateSuite</td><td>closed</td><td>2025-07-01T23:29:46.000Z</td><td>cloud-fan</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193514362</td><td>51341</td><td>[SPARK-52570][PS] Enable divide-by-zero for numeric rmod with ANSI enabled</td><td>closed</td><td>2025-07-01T21:25:21.000Z</td><td>ueshin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3193230593</td><td>51338</td><td>[SPARK-52636][K8S] Support `java_image_name` ARG in K8s `Dockerfile`</td><td>closed</td><td>2025-07-01T19:44:57.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3192122466</td><td>51335</td><td>[WIP] Fix inconsistencies and refactor primitive types in parser</td><td>open</td><td>2025-07-01T16:02:06.000Z</td><td>mihailom-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3156661637</td><td>51215</td><td>[SPARK-52444][SQL][CONNECT] Add support for Variant/Char/Varchar Literal</td><td>open</td><td>2025-07-01T11:35:06.000Z</td><td>dengziming</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190838933</td><td>51328</td><td>[SPARK-52515][SQL][TESTS][FOLLOW-UP] Explicitly enable ANSI for overflow error case</td><td>closed</td><td>2025-07-01T09:47:28.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3163640796</td><td>51233</td><td>[SPARK-52539][CONNECT] Introduce session hooks</td><td>closed</td><td>2025-07-01T09:44:38.000Z</td><td>niklasmohrin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190857838</td><td>51330</td><td>[SPARK-52551][SQL][TESTS][FOLLOW-UP] Explicitly enable ANSI for the test case in V2 cast pushdown</td><td>closed</td><td>2025-07-01T08:37:56.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164896881</td><td>51239</td><td>[SPARK-51035][BUILD] Upgrade Janino to 3.1.12</td><td>open</td><td>2025-07-01T07:42:26.000Z</td><td>YanivKunda</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190222252</td><td>51325</td><td>[SPARK-52626][SQL] Allow grouping by the time type</td><td>closed</td><td>2025-07-01T06:24:40.000Z</td><td>bersprockets</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3168310314</td><td>51247</td><td>[SPARK-52551][SQL] Add a new v2 Predicate BOOLEAN_EXPRESSION</td><td>closed</td><td>2025-07-01T06:05:37.000Z</td><td>cloud-fan</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3173341805</td><td>51275</td><td>[SPARK-52570][PS] Enable divide-by-zero for numeric rmod with ANSI enabled</td><td>closed</td><td>2025-07-01T05:50:55.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3178187170</td><td>51292</td><td>[WIP][PYTHON] Arrow UDF for aggregation</td><td>open</td><td>2025-07-01T02:12:32.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3190269431</td><td>51326</td><td>[WIP][SPARK-52622][PS] Avoid CAST_INVALID_INPUT of `DataFrame.melt` in ANSI mode</td><td>open</td><td>2025-07-01T00:37:13.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3163768830</td><td>51234</td><td>[SPARK-52541] [SDP] Add programming guide for Declarative Pipelines</td><td>closed</td><td>2025-06-30T23:05:21.000Z</td><td>sryza</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3184192823</td><td>51310</td><td>[SPARK-52593][PS] Avoid CAST_INVALID_INPUT of `Series.dot` and `DataFrame.dot` in ANSI mode</td><td>open</td><td>2025-06-30T22:26:29.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3189535457</td><td>51324</td><td>changed Deprecated to lower case pull request</td><td>closed</td><td>2025-06-30T18:59:49.000Z</td><td>larryleinweber</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170008299</td><td>51257</td><td>[SPARK-52560][BUILD] Bump ap-loader 4.0(v10) to support for async-profiler 4.0</td><td>open</td><td>2025-06-30T16:36:26.000Z</td><td>wForget</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3185581779</td><td>51315</td><td>[SPARK-52609][SQL] Make sure row sorter from each task won't be overwritten by other tasks in parallel</td><td>closed</td><td>2025-06-30T15:13:52.000Z</td><td>viirya</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170410365</td><td>51262</td><td>[SPARK-52610][BUILD] Upgrade rocksdbjni to 10.2.1</td><td>closed</td><td>2025-06-30T14:48:31.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183020890</td><td>51303</td><td>[SPARK-52596][SQL] Try make TIMESTAMP_NTZ from DATE and TIME</td><td>closed</td><td>2025-06-30T14:32:48.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177123996</td><td>51285</td><td>[SPARK-52578][SQL] Add metrics for rows to track case and action in MergeRowsExec</td><td>closed</td><td>2025-06-30T14:29:15.000Z</td><td>szehon-ho</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3176575187</td><td>51281</td><td>[SPARK-52497][DOCS] Add docs for SQL user-defined functions</td><td>closed</td><td>2025-06-30T13:34:34.000Z</td><td>allisonwang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177097057</td><td>51284</td><td>[CORE] Let LocalSparkContext clear active context in beforeAll</td><td>open</td><td>2025-06-30T09:24:24.000Z</td><td>price-qian</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3184899143</td><td>51312</td><td>[SPARK-52381][CORE][4.0] JsonProtocol: Only accept subclasses of SparkListenerEvent</td><td>closed</td><td>2025-06-30T09:06:39.000Z</td><td>pjfanning</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3184633217</td><td>51311</td><td>[SPARK-52600][CONNECT] Move CompletionIterator to common/utils</td><td>closed</td><td>2025-06-30T07:51:33.000Z</td><td>huanliwang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3185791610</td><td>51316</td><td>[MINOR][DOCS] Updated the docstring of DataStreamWriter.foreach() method</td><td>open</td><td>2025-06-30T07:50:11.000Z</td><td>nagaarjun-p</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187028883</td><td>51318</td><td>[SPARK-52611][SQL] Fix SQLConf version for excludeSubqueryRefsFromRemoveRedundantAliasesâ€¦</td><td>closed</td><td>2025-06-30T07:49:04.000Z</td><td>atongpu</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3184104476</td><td>51309</td><td>[SPARK-52599][PYTHON] Support periodical traceback dump in Driver side workers</td><td>closed</td><td>2025-06-30T07:44:20.000Z</td><td>ueshin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3184923866</td><td>51313</td><td>[SPARK-52601][SQL] Support primitive types in TransformingEncoder</td><td>open</td><td>2025-06-30T06:38:27.000Z</td><td>eejbyfeldt</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3187244808</td><td>51319</td><td>[SPARK-52614][SQL] Support RowEncoder inside Product Encoder</td><td>open</td><td>2025-06-30T06:38:16.000Z</td><td>eejbyfeldt</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3182218562</td><td>51302</td><td>[SPARK-52595][SQL] Rename the `TimeAdd` expression to `TimestampAddInterval`</td><td>closed</td><td>2025-06-30T02:57:01.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3182131659</td><td>51301</td><td>[SPARK-52594][DOCS] Workaround pandas version string issue in doc generation</td><td>closed</td><td>2025-06-30T02:00:23.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3181329031</td><td>51300</td><td>[SPARK-52592][PS] Prevent error when creating ps.Series from ps.Series</td><td>open</td><td>2025-06-29T23:16:38.000Z</td><td>petern48</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3185994352</td><td>51317</td><td>[SPARK-51051][SQL]Add an optional parameter for `array_position` function to specify starting index for matching.</td><td>open</td><td>2025-06-29T11:50:50.000Z</td><td>konjac</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3185338490</td><td>51314</td><td>[SPARK-46912][CORE] Using correct environment variables on workers of StandAlone cluster</td><td>open</td><td>2025-06-28T18:06:00.000Z</td><td>MeltonSmith</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183618687</td><td>51306</td><td>[SPARK-46912][CORE] Using correct environment variables on workers of StandAlone cluster</td><td>closed</td><td>2025-06-28T17:39:59.000Z</td><td>MeltonSmith</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183265874</td><td>51305</td><td>[SPARK-52598][DOCS] Reorganize Spark Connect programming guide</td><td>open</td><td>2025-06-28T16:28:35.000Z</td><td>nchammas</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183180461</td><td>51304</td><td>[SPARK-52597][SS][TESTS] Fix the execution failure of `StateStoreBasicOperationsBenchmark`</td><td>closed</td><td>2025-06-28T04:51:59.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183763635</td><td>51308</td><td>[SPARK-52588][SQL] Approx_top_k: accumulate, combine, estimate</td><td>open</td><td>2025-06-27T23:24:26.000Z</td><td>yhuang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3180954046</td><td>51298</td><td>[SPARK-52407][SQL] Add support for Theta Sketch</td><td>open</td><td>2025-06-27T22:59:38.000Z</td><td>cboumalh</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172951687</td><td>51274</td><td>[SPARK-51885][SQL] Change AnalysisContext.outerPlan from Option[LogicalPlan] to Seq[LogicalPlan]</td><td>open</td><td>2025-06-27T19:57:02.000Z</td><td>AveryQi115</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3183670788</td><td>51307</td><td>[SPARK-52188] [FOLLOWUP] Update comment in getRunId</td><td>closed</td><td>2025-06-27T18:12:14.000Z</td><td>WweiL</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170782573</td><td>51264</td><td>SPARK-52564 configuration changes not require deleting the checkpoint</td><td>open</td><td>2025-06-27T17:42:16.000Z</td><td>sohurdc</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169426214</td><td>51251</td><td>[SPARK-52552][SQL] Skip CHECK constraint enforcement for deletion vector deletes</td><td>closed</td><td>2025-06-27T17:01:42.000Z</td><td>gengliangwang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3180339545</td><td>51296</td><td>[SPARK-52590][SQL][TESTS] Add SQL query tests for SQL functions without explicit return types</td><td>closed</td><td>2025-06-27T14:04:38.000Z</td><td>allisonwang-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170841122</td><td>51265</td><td>[SPARK-52518][SQL][TEST] Fix `AddMetadataColumnsSuite` package path</td><td>closed</td><td>2025-06-27T13:08:03.000Z</td><td>xu20160924</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177604692</td><td>51289</td><td>[SPARK-52583][SQL] Add an Developer API for stringifying values in UserDefinedType</td><td>closed</td><td>2025-06-27T09:28:18.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3178444904</td><td>51293</td><td>[SPARK-52586][SQL] Introduce AnyTimeType</td><td>closed</td><td>2025-06-27T07:34:21.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3181014378</td><td>51299</td><td>[SPARK-52547][INFRA][FOLLOW-UP] Set default GIT_BRANCH even for scheduled jobs</td><td>closed</td><td>2025-06-27T03:45:49.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3179098614</td><td>51294</td><td>[SPARK-52587][SHELL] spark-shell 2.13 support `-i` `-I` parameter</td><td>closed</td><td>2025-06-27T02:59:16.000Z</td><td>cxzl25</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177513597</td><td>51288</td><td>[SPARK-52568][BUILD][3.5] Fix `exec-maven-plugin` version used by `dev/test-dependencies.sh`</td><td>closed</td><td>2025-06-27T00:55:29.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3179171851</td><td>51295</td><td>Fix-AQE-OOM</td><td>open</td><td>2025-06-26T13:39:02.000Z</td><td>zhixingheyi-tian</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177990162</td><td>51291</td><td>[SPARK-52584][BUILD] Make build script to support preview releases in finalize step</td><td>closed</td><td>2025-06-26T06:49:27.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177923163</td><td>51290</td><td>[SPARK-50686][SQL] Hash to sort aggregation fallback - memory usage optimization</td><td>open</td><td>2025-06-26T06:20:07.000Z</td><td>akupchinskiy</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3177160576</td><td>51286</td><td>[SPARK-52579][PYTHON] Set periodical traceback dump for Python workers</td><td>closed</td><td>2025-06-26T03:50:55.000Z</td><td>ueshin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3161652170</td><td>51226</td><td>[SPARK-52534][ML][CONNECT] Make MLCache and MLHandler thread-safe</td><td>closed</td><td>2025-06-26T03:01:29.000Z</td><td>WeichenXu123</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172685460</td><td>51273</td><td>[SPARK-52568][BUILD] Fix `exec-maven-plugin` version used by `dev/test-dependencies.sh`</td><td>closed</td><td>2025-06-26T02:29:15.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3174448831</td><td>51278</td><td>[SPARK-52573][PYTHON][TESTS] Add tests for decimal type</td><td>closed</td><td>2025-06-26T00:36:30.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3173477267</td><td>51276</td><td>[SPARK-52572][PS] Avoid CAST_INVALID_INPUT of DataFrame.isin in ANSI mode </td><td>closed</td><td>2025-06-26T00:26:23.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3174912667</td><td>51279</td><td>[SPARK-52574][SQL][TESTS] Ensure compression codec is correctly applied in Hive tables and dirs</td><td>closed</td><td>2025-06-25T22:50:14.000Z</td><td>wangyum</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3176916529</td><td>51283</td><td>[SDP] [SPARK-52577] Add tests for Declarative Pipelines DatasetManager with Hive catalog</td><td>open</td><td>2025-06-25T20:46:02.000Z</td><td>sryza</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172276576</td><td>51268</td><td>[SPARK-52565] [SQL] Enforce ordinal resolution before other sort order expressions</td><td>open</td><td>2025-06-25T19:30:01.000Z</td><td>mihailoale-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172483289</td><td>51271</td><td>[SPARK-52567][SQL][HIVE][TEST] Refactor Hive_2_1_DDLSuite</td><td>closed</td><td>2025-06-25T17:34:42.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3159409972</td><td>51223</td><td>[SPARK-52533] Support enabling only driver profiler</td><td>closed</td><td>2025-06-25T17:25:23.000Z</td><td>wForget</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172335808</td><td>51269</td><td>[SPARK-37467][SQL] Consolidate subexpression elimination code for whole stage and non-whole stage</td><td>open</td><td>2025-06-25T17:00:42.000Z</td><td>Kimahriman</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172377055</td><td>51270</td><td>[SPARK-52569][SQL] Fix the class cast exception in `SecondsOfTimeWithFraction`</td><td>closed</td><td>2025-06-25T13:41:38.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3174116201</td><td>51277</td><td>[PYTHON][MINOR] Decrease default `arrowMaxBytesPerBatch` for arrow-optimized UDF</td><td>closed</td><td>2025-06-25T07:29:07.000Z</td><td>asl3</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170504750</td><td>51263</td><td>[SPARK-52339][SQL][FOLLOWUP] Sort paths in InMemoryFileIndex#equal only when size matches</td><td>closed</td><td>2025-06-25T02:15:33.000Z</td><td>yaooqinn</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170126405</td><td>51260</td><td>[SPARK-52562][INFRA] Automatically create the base of release notes and push</td><td>closed</td><td>2025-06-24T23:42:30.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3171648927</td><td>51266</td><td>[SPARK-52547][INFRA][FOLLOW-UP] Check RELEASE_VERSION and SPARK_RC_COUNT for dryruns</td><td>closed</td><td>2025-06-24T23:26:36.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169677362</td><td>51254</td><td>[SPARK-52557][PS] Avoid CAST_INVALID_INPUT of to_numeric(errors='coerce') in ANSI mode</td><td>closed</td><td>2025-06-24T21:28:09.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172492030</td><td>51272</td><td>[SPARK-37466][SQL] Support subexpression elimination in higher order functions</td><td>open</td><td>2025-06-24T20:23:21.000Z</td><td>Kimahriman</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170318376</td><td>51261</td><td>Revert \"[SPARK-50849][CONNECT] Add example project to demonstrate Spark Connect Server Libraries\"</td><td>closed</td><td>2025-06-24T16:28:43.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3167269028</td><td>51246</td><td>[SPARK-52548][CORE][TESTS] Add a test case for when shuffle manager is overridden by a SparkPlugin</td><td>closed</td><td>2025-06-24T16:25:13.000Z</td><td>zhztheplayer</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3172233702</td><td>51267</td><td>[SPARK-50603][SQL] Respect user-provided basePath for streaming file source reads without glob</td><td>open</td><td>2025-06-24T14:30:48.000Z</td><td>Kimahriman</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3170086199</td><td>51258</td><td>[SPARK-52470][ML][PYTHON][FOLLOW-UP] Further fix GRPC import</td><td>closed</td><td>2025-06-24T07:53:50.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3168409961</td><td>51248</td><td>[SPARK-52460][SQL][FOLLOWUP] Fix names and test ranges of TIME values</td><td>closed</td><td>2025-06-24T07:06:15.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169672461</td><td>51253</td><td>[SPARK-52563][PS] Fix var naming bug in _assert_pandas_almost_equal</td><td>open</td><td>2025-06-24T06:32:05.000Z</td><td>petern48</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169907463</td><td>51256</td><td>[SPARK-52339][SQL][3.5] Fix comparison of `InMemoryFileIndex` instances</td><td>closed</td><td>2025-06-24T06:11:19.000Z</td><td>bersprockets</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169729266</td><td>51255</td><td>[SPARK-52553][SS] Fix NumberFormatException when reading v1 changelog</td><td>closed</td><td>2025-06-24T04:34:00.000Z</td><td>micheal-o</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3166050073</td><td>51243</td><td>[SPARK-52546][SQL] check sparkContext if has stopped when running catch code block in execute(), otherwise, it will return wrong state.</td><td>closed</td><td>2025-06-24T01:46:49.000Z</td><td>xuyu-co</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3162430028</td><td>51229</td><td>[SPARK-52536] Set AsyncProfilerLoader extractionDir to spark local dir</td><td>closed</td><td>2025-06-24T00:22:13.000Z</td><td>wForget</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169648510</td><td>51252</td><td>[SPARK-52554][PS] Avoid multiple roundtrips for config check in Spark Connect</td><td>closed</td><td>2025-06-24T00:21:09.000Z</td><td>ueshin</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3166997826</td><td>51245</td><td>[SPARK-52547][INFRA] Build dry runs against master branch</td><td>closed</td><td>2025-06-23T23:52:22.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169135135</td><td>51249</td><td>[SPARK-52349][PS] Enable boolean division tests with ANSI enabled</td><td>closed</td><td>2025-06-23T20:52:05.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3169315157</td><td>51250</td><td>Test Apache ORC 1.8.10 RC0</td><td>closed</td><td>2025-06-23T20:09:02.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3163476334</td><td>51232</td><td>[SPARK-52540][SQL] Make TIMESTAMP_NTZ from DATE and TIME</td><td>closed</td><td>2025-06-23T16:36:15.000Z</td><td>MaxGekk</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164131013</td><td>51235</td><td>[SPARK-52544][SQL] Allow configuring Json datasource string length limit through SQLConf</td><td>open</td><td>2025-06-23T08:53:21.000Z</td><td>tianhanhu</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3163211460</td><td>51231</td><td>[SPARK-52538][SQL] Add new method to check if the value is fully extractable</td><td>closed</td><td>2025-06-23T07:17:14.000Z</td><td>vladimirg-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3166656562</td><td>51244</td><td>[SPARK-52422][BUILD][FOLLOW-UP] Pin pandas as 2.2.3 for release build</td><td>closed</td><td>2025-06-23T06:47:44.000Z</td><td>HyukjinKwon</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3157477307</td><td>51216</td><td>[SPARK-52531][SQL] `OuterReference` in subquery aggregate is incorrectly tied to outer query aggregate</td><td>closed</td><td>2025-06-23T03:12:06.000Z</td><td>mihailotim-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3159459112</td><td>51224</td><td>[SPARK-52532][SQL][TESTS] Add tests for hidden or main output prioritization during attribute name conflict</td><td>closed</td><td>2025-06-23T02:54:31.000Z</td><td>vladimirg-db</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164912210</td><td>51241</td><td>[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test</td><td>open</td><td>2025-06-23T02:45:15.000Z</td><td>ikshitiz</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3158723263</td><td>51222</td><td>[SPARK-52530][SQL][TESTS] Move `SimpleTestOptimizer` to test source directory</td><td>closed</td><td>2025-06-23T02:32:30.000Z</td><td>LuciferYang</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3158254496</td><td>51219</td><td> [SPARK-52528][PS] Enable divide-by-zero for numeric mod with ANSI enabled</td><td>closed</td><td>2025-06-23T02:24:46.000Z</td><td>xinrong-meng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164902661</td><td>51240</td><td>[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test</td><td>open</td><td>2025-06-21T08:19:17.000Z</td><td>ikshitiz</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164886105</td><td>51237</td><td>[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test</td><td>closed</td><td>2025-06-21T08:19:13.000Z</td><td>ikshitiz</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3164896683</td><td>51238</td><td>Initial commit</td><td>open</td><td>2025-06-21T08:09:41.000Z</td><td>Raghavdodla</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3162243699</td><td>51228</td><td>[SPARK-52537][CORE] Print stacktrace on creating temp dir failure</td><td>closed</td><td>2025-06-20T18:08:31.000Z</td><td>pan3793</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3158684960</td><td>51221</td><td>[Test]</td><td>open</td><td>2025-06-19T14:40:57.000Z</td><td>WeichenXu123</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3158657228</td><td>51220</td><td>[SPARK-52470][TESTS][FOLLOWUP] Fix test failure caused by import connect in pure classic testing envs</td><td>closed</td><td>2025-06-19T02:43:03.000Z</td><td>zhengruifeng</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3157520210</td><td>51217</td><td>[SPARK-52527][BUILD] Upgrade `junit` to 5.13.1</td><td>closed</td><td>2025-06-19T02:20:09.000Z</td><td>dongjoon-hyun</td><td>2025-07-03T13:44:46.381Z</td></tr><tr><td>3157608084</td><td>51218</td><td>Feature/spark 44647 backport 3.5.6</td><td>closed</td><td>2025-06-18T17:22:11.000Z</td><td>IgorBerman</td><td>2025-07-03T13:44:46.381Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3199460855,
         51364,
         "[SPARK-52675][ML][CONNECT] Interrupt hanging ML handlers in tests",
         "open",
         "2025-07-03T13:44:39.000Z",
         "WeichenXu123",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198911743,
         51361,
         "[WIP][SPARK-52618][SQL] Casting TIME(n) to TIME(m)",
         "open",
         "2025-07-03T13:08:37.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3197564924,
         51354,
         "[SPARK-52660][SQL] Add time type to `CodeGenerator#javaClass`",
         "closed",
         "2025-07-03T12:23:07.000Z",
         "bersprockets",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198964388,
         51363,
         "[SPARK-52673][CONNECT][CLIENT] Add grpc RetryInfo handling to Spark Connect retry policies",
         "open",
         "2025-07-03T12:22:06.000Z",
         "khakhlyuk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198921208,
         51362,
         "[SPARK-52674][SQL] Clean up the usage of deprecated APIs related to `RandomStringUtils`",
         "open",
         "2025-07-03T10:49:51.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3161928074,
         51227,
         "[SPARK-52535][SQL] Improve code readability of rule ApplyColumnarRulesAndInsertTransitions",
         "closed",
         "2025-07-03T10:33:52.000Z",
         "zhztheplayer",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198817544,
         51360,
         "[SPARK-52671][SQL] RowEncoder shall not lookup a resolved UDT",
         "open",
         "2025-07-03T10:04:31.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198708344,
         51359,
         "[SPARK-52672][SQL] Don't replace Sort/Having expressions with aliases if expression exists in Aggregate",
         "open",
         "2025-07-03T09:47:59.000Z",
         "mihailotim-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187748015,
         51323,
         "[SPARK-52381][CORE][3.5] JsonProtocol: Only accept subclasses of SparkListenerEvent",
         "closed",
         "2025-07-03T09:35:46.000Z",
         "pjfanning",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3197859941,
         51355,
         "[SPARK-52665][BUILD] Fix make-distribution.sh [: missing `]'",
         "open",
         "2025-07-03T09:24:50.000Z",
         "cxzl25",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3196488081,
         51351,
         "[SPARK-52656][SQL] Fix current_time()",
         "closed",
         "2025-07-03T09:20:35.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193084236,
         51337,
         "[WIP][SQL][TESTS] Disable stable column aliases in tests if assumed",
         "open",
         "2025-07-03T08:55:23.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170102244,
         51259,
         "[SPARK-52561][PYTHON][INFRA] Upgrade the minimum version of Python to 3.10",
         "open",
         "2025-07-03T08:44:46.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3176493991,
         51280,
         "[SDP] [SPARK-52576] Drop/recreate on full refresh and MV update",
         "open",
         "2025-07-03T08:19:22.000Z",
         "sryza",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3176799950,
         51282,
         "[SPARK-52575][SQL] Introduce contextIndependentFoldable attribute for Expressions",
         "open",
         "2025-07-03T08:09:34.000Z",
         "gengliangwang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193628652,
         51342,
         "[SPARK-52638][SQL] Allow preserving Hive-style column order to be configurable",
         "open",
         "2025-07-03T08:03:32.000Z",
         "szehon-ho",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198362916,
         51357,
         "[SPARK-52669][PySpark]Improvement PySpark choose pythonExec in cluster yarn client mode",
         "open",
         "2025-07-03T07:41:46.000Z",
         "gwdgithubnom",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3198394330,
         51358,
         "[SPARK-52670][SQL] Make HiveResult work with UserDefinedType#stringifyValue",
         "open",
         "2025-07-03T07:39:42.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187248572,
         51320,
         "[SPARK-52613][CORE][SQL] Restore printing full stacktrace when HBase/Hive DelegationTokenProvider hit exception",
         "closed",
         "2025-07-03T07:32:19.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193300501,
         51339,
         "[SPARK-52649][SQL] Trim aliases before matching Sort/Having/Filter expressions in `buildAggExprList`",
         "closed",
         "2025-07-03T07:28:50.000Z",
         "mihailotim-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187462351,
         51322,
         "[SPARK-52615][CORE] Replace File.mkdirs with Utils.createDirectory",
         "closed",
         "2025-07-03T06:44:57.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3197555691,
         51353,
         "[SPARK-52663][SDP] Introduce name field to pipeline spec",
         "open",
         "2025-07-03T06:27:09.000Z",
         "sryza",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3191401184,
         51332,
         "[SPARK-52632][SQL] Pretty display V2 write plan nodes",
         "open",
         "2025-07-03T05:42:08.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3197917883,
         51356,
         "[SPARK-52666][SQL] Map User Defined Type to correct MutableValue in SpecificInternalRow",
         "open",
         "2025-07-03T04:02:12.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3162505926,
         51230,
         "[WIP][SPARK-51224][BUILD] Test Maven 4",
         "open",
         "2025-07-03T03:53:27.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190819641,
         51327,
         "[SPARK-52630][SS] Reorganize streaming operator and state mgmt code and dirs",
         "closed",
         "2025-07-03T03:01:51.000Z",
         "anishshri-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3195020198,
         51348,
         "[SPARK-52503][SQL][CONNECT][4.0] Fix drop when the input column is not existent",
         "closed",
         "2025-07-03T02:41:04.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3195539118,
         51349,
         "[SPARK-52651][SQL] Handle User Defined Type in Nested ColumnVector",
         "closed",
         "2025-07-03T01:49:20.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177450990,
         51287,
         "[SPARK-52582][SQL] Improve the memory usage of XML parser",
         "open",
         "2025-07-03T00:01:54.000Z",
         "xiaonanyang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193706249,
         51344,
         "[SPARK-52640][SDP] Propagate Python Source Code Location",
         "open",
         "2025-07-02T23:15:21.000Z",
         "AnishMahto",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3180839163,
         51297,
         "[SPARK-52580][PS] Avoid CAST_INVALID_INPUT of `replace` in ANSI mode",
         "open",
         "2025-07-02T22:28:15.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164441897,
         51236,
         "[SPARK-52515][SQL] Add approx_top_k function",
         "closed",
         "2025-07-02T22:27:31.000Z",
         "yhuang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193463767,
         51340,
         "[SS][SPARK-52637] Fix version ID mismatch issue for RocksDB compaction leading to incorrect file mapping",
         "open",
         "2025-07-02T22:26:40.000Z",
         "liviazhu",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190893225,
         51331,
         "[SPARK-52539][CONNECT][FOLLOW-UP] Avoid using TypeAlias that is available from Python 3.10",
         "closed",
         "2025-07-02T22:25:54.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3165942571,
         51242,
         "[SPARK-52545][SQL] Standardize double-quote escaping to follow SQL specification",
         "closed",
         "2025-07-02T22:24:01.000Z",
         "dengziming",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3192082330,
         51334,
         "[SPARK-52633][SQL] Deduplicate single `Union` child output before `DeduplicateRelations`",
         "closed",
         "2025-07-02T22:21:08.000Z",
         "mihailotim-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3194809460,
         51347,
         "[SPARK-52023][SQL][3.5] Fix data corruption/segfault returning Option[Product] from udaf",
         "closed",
         "2025-07-02T22:18:17.000Z",
         "eejbyfeldt",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3195805678,
         51350,
         "[SPARK-52652][BUILD] Replace `os-maven-plugin` with `nisse`",
         "closed",
         "2025-07-02T21:42:34.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3191593929,
         51333,
         "[SPARK-52634][SQL][DOCS] Update the ANSI compliance page regarding the TIME type",
         "open",
         "2025-07-02T17:20:27.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3196566453,
         51352,
         "[SPARK-52409][SDP] Only use PipelineRunEventBuffer in tests",
         "open",
         "2025-07-02T17:10:35.000Z",
         "sryza",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3192826296,
         51336,
         "[SPARK-52635][BUILD][3.5] Upgrade ORC to 1.9.7",
         "open",
         "2025-07-02T04:48:26.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187299651,
         51321,
         "[SPARK-52612][INFRA] Add an env `NO_PROVIDED_SPARK_JARS` to control collection behavior of `sbt/package` for `spark-avro.jar` and `spark-protobuf.jar`",
         "closed",
         "2025-07-02T04:11:09.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193634752,
         51343,
         "[SPARK-52639][K8S][INFRA][DOCS] Upgrade Volcano to 1.12.1",
         "closed",
         "2025-07-02T04:00:35.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3194038302,
         51346,
         "[SPARK-52643][BUILD] Upgrade `extra-enforcer-rules` to support Java 25",
         "closed",
         "2025-07-02T04:00:16.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193966871,
         51345,
         "[SPARK-52642][PYTHON] Use daemonWorkers.get(worker) to avoid unexpected out-of-sync between idleWorkers and daemonWorkers",
         "closed",
         "2025-07-02T02:34:30.000Z",
         "ueshin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3161287345,
         51225,
         "[DRAFT][PYTHON] Improve Python UDF Arrow Serializer Performance",
         "open",
         "2025-07-01T23:40:05.000Z",
         "asl3",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190857829,
         51329,
         "[SPARK-52551][SQL][FOLLOW-UP] Enable ANSI mode in PushablePredicateSuite",
         "closed",
         "2025-07-01T23:29:46.000Z",
         "cloud-fan",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193514362,
         51341,
         "[SPARK-52570][PS] Enable divide-by-zero for numeric rmod with ANSI enabled",
         "closed",
         "2025-07-01T21:25:21.000Z",
         "ueshin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3193230593,
         51338,
         "[SPARK-52636][K8S] Support `java_image_name` ARG in K8s `Dockerfile`",
         "closed",
         "2025-07-01T19:44:57.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3192122466,
         51335,
         "[WIP] Fix inconsistencies and refactor primitive types in parser",
         "open",
         "2025-07-01T16:02:06.000Z",
         "mihailom-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3156661637,
         51215,
         "[SPARK-52444][SQL][CONNECT] Add support for Variant/Char/Varchar Literal",
         "open",
         "2025-07-01T11:35:06.000Z",
         "dengziming",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190838933,
         51328,
         "[SPARK-52515][SQL][TESTS][FOLLOW-UP] Explicitly enable ANSI for overflow error case",
         "closed",
         "2025-07-01T09:47:28.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3163640796,
         51233,
         "[SPARK-52539][CONNECT] Introduce session hooks",
         "closed",
         "2025-07-01T09:44:38.000Z",
         "niklasmohrin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190857838,
         51330,
         "[SPARK-52551][SQL][TESTS][FOLLOW-UP] Explicitly enable ANSI for the test case in V2 cast pushdown",
         "closed",
         "2025-07-01T08:37:56.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164896881,
         51239,
         "[SPARK-51035][BUILD] Upgrade Janino to 3.1.12",
         "open",
         "2025-07-01T07:42:26.000Z",
         "YanivKunda",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190222252,
         51325,
         "[SPARK-52626][SQL] Allow grouping by the time type",
         "closed",
         "2025-07-01T06:24:40.000Z",
         "bersprockets",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3168310314,
         51247,
         "[SPARK-52551][SQL] Add a new v2 Predicate BOOLEAN_EXPRESSION",
         "closed",
         "2025-07-01T06:05:37.000Z",
         "cloud-fan",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3173341805,
         51275,
         "[SPARK-52570][PS] Enable divide-by-zero for numeric rmod with ANSI enabled",
         "closed",
         "2025-07-01T05:50:55.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3178187170,
         51292,
         "[WIP][PYTHON] Arrow UDF for aggregation",
         "open",
         "2025-07-01T02:12:32.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3190269431,
         51326,
         "[WIP][SPARK-52622][PS] Avoid CAST_INVALID_INPUT of `DataFrame.melt` in ANSI mode",
         "open",
         "2025-07-01T00:37:13.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3163768830,
         51234,
         "[SPARK-52541] [SDP] Add programming guide for Declarative Pipelines",
         "closed",
         "2025-06-30T23:05:21.000Z",
         "sryza",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3184192823,
         51310,
         "[SPARK-52593][PS] Avoid CAST_INVALID_INPUT of `Series.dot` and `DataFrame.dot` in ANSI mode",
         "open",
         "2025-06-30T22:26:29.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3189535457,
         51324,
         "changed Deprecated to lower case pull request",
         "closed",
         "2025-06-30T18:59:49.000Z",
         "larryleinweber",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170008299,
         51257,
         "[SPARK-52560][BUILD] Bump ap-loader 4.0(v10) to support for async-profiler 4.0",
         "open",
         "2025-06-30T16:36:26.000Z",
         "wForget",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3185581779,
         51315,
         "[SPARK-52609][SQL] Make sure row sorter from each task won't be overwritten by other tasks in parallel",
         "closed",
         "2025-06-30T15:13:52.000Z",
         "viirya",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170410365,
         51262,
         "[SPARK-52610][BUILD] Upgrade rocksdbjni to 10.2.1",
         "closed",
         "2025-06-30T14:48:31.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183020890,
         51303,
         "[SPARK-52596][SQL] Try make TIMESTAMP_NTZ from DATE and TIME",
         "closed",
         "2025-06-30T14:32:48.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177123996,
         51285,
         "[SPARK-52578][SQL] Add metrics for rows to track case and action in MergeRowsExec",
         "closed",
         "2025-06-30T14:29:15.000Z",
         "szehon-ho",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3176575187,
         51281,
         "[SPARK-52497][DOCS] Add docs for SQL user-defined functions",
         "closed",
         "2025-06-30T13:34:34.000Z",
         "allisonwang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177097057,
         51284,
         "[CORE] Let LocalSparkContext clear active context in beforeAll",
         "open",
         "2025-06-30T09:24:24.000Z",
         "price-qian",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3184899143,
         51312,
         "[SPARK-52381][CORE][4.0] JsonProtocol: Only accept subclasses of SparkListenerEvent",
         "closed",
         "2025-06-30T09:06:39.000Z",
         "pjfanning",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3184633217,
         51311,
         "[SPARK-52600][CONNECT] Move CompletionIterator to common/utils",
         "closed",
         "2025-06-30T07:51:33.000Z",
         "huanliwang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3185791610,
         51316,
         "[MINOR][DOCS] Updated the docstring of DataStreamWriter.foreach() method",
         "open",
         "2025-06-30T07:50:11.000Z",
         "nagaarjun-p",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187028883,
         51318,
         "[SPARK-52611][SQL] Fix SQLConf version for excludeSubqueryRefsFromRemoveRedundantAliasesâ€¦",
         "closed",
         "2025-06-30T07:49:04.000Z",
         "atongpu",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3184104476,
         51309,
         "[SPARK-52599][PYTHON] Support periodical traceback dump in Driver side workers",
         "closed",
         "2025-06-30T07:44:20.000Z",
         "ueshin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3184923866,
         51313,
         "[SPARK-52601][SQL] Support primitive types in TransformingEncoder",
         "open",
         "2025-06-30T06:38:27.000Z",
         "eejbyfeldt",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3187244808,
         51319,
         "[SPARK-52614][SQL] Support RowEncoder inside Product Encoder",
         "open",
         "2025-06-30T06:38:16.000Z",
         "eejbyfeldt",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3182218562,
         51302,
         "[SPARK-52595][SQL] Rename the `TimeAdd` expression to `TimestampAddInterval`",
         "closed",
         "2025-06-30T02:57:01.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3182131659,
         51301,
         "[SPARK-52594][DOCS] Workaround pandas version string issue in doc generation",
         "closed",
         "2025-06-30T02:00:23.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3181329031,
         51300,
         "[SPARK-52592][PS] Prevent error when creating ps.Series from ps.Series",
         "open",
         "2025-06-29T23:16:38.000Z",
         "petern48",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3185994352,
         51317,
         "[SPARK-51051][SQL]Add an optional parameter for `array_position` function to specify starting index for matching.",
         "open",
         "2025-06-29T11:50:50.000Z",
         "konjac",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3185338490,
         51314,
         "[SPARK-46912][CORE] Using correct environment variables on workers of StandAlone cluster",
         "open",
         "2025-06-28T18:06:00.000Z",
         "MeltonSmith",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183618687,
         51306,
         "[SPARK-46912][CORE] Using correct environment variables on workers of StandAlone cluster",
         "closed",
         "2025-06-28T17:39:59.000Z",
         "MeltonSmith",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183265874,
         51305,
         "[SPARK-52598][DOCS] Reorganize Spark Connect programming guide",
         "open",
         "2025-06-28T16:28:35.000Z",
         "nchammas",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183180461,
         51304,
         "[SPARK-52597][SS][TESTS] Fix the execution failure of `StateStoreBasicOperationsBenchmark`",
         "closed",
         "2025-06-28T04:51:59.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183763635,
         51308,
         "[SPARK-52588][SQL] Approx_top_k: accumulate, combine, estimate",
         "open",
         "2025-06-27T23:24:26.000Z",
         "yhuang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3180954046,
         51298,
         "[SPARK-52407][SQL] Add support for Theta Sketch",
         "open",
         "2025-06-27T22:59:38.000Z",
         "cboumalh",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172951687,
         51274,
         "[SPARK-51885][SQL] Change AnalysisContext.outerPlan from Option[LogicalPlan] to Seq[LogicalPlan]",
         "open",
         "2025-06-27T19:57:02.000Z",
         "AveryQi115",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3183670788,
         51307,
         "[SPARK-52188] [FOLLOWUP] Update comment in getRunId",
         "closed",
         "2025-06-27T18:12:14.000Z",
         "WweiL",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170782573,
         51264,
         "SPARK-52564 configuration changes not require deleting the checkpoint",
         "open",
         "2025-06-27T17:42:16.000Z",
         "sohurdc",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169426214,
         51251,
         "[SPARK-52552][SQL] Skip CHECK constraint enforcement for deletion vector deletes",
         "closed",
         "2025-06-27T17:01:42.000Z",
         "gengliangwang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3180339545,
         51296,
         "[SPARK-52590][SQL][TESTS] Add SQL query tests for SQL functions without explicit return types",
         "closed",
         "2025-06-27T14:04:38.000Z",
         "allisonwang-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170841122,
         51265,
         "[SPARK-52518][SQL][TEST] Fix `AddMetadataColumnsSuite` package path",
         "closed",
         "2025-06-27T13:08:03.000Z",
         "xu20160924",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177604692,
         51289,
         "[SPARK-52583][SQL] Add an Developer API for stringifying values in UserDefinedType",
         "closed",
         "2025-06-27T09:28:18.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3178444904,
         51293,
         "[SPARK-52586][SQL] Introduce AnyTimeType",
         "closed",
         "2025-06-27T07:34:21.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3181014378,
         51299,
         "[SPARK-52547][INFRA][FOLLOW-UP] Set default GIT_BRANCH even for scheduled jobs",
         "closed",
         "2025-06-27T03:45:49.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3179098614,
         51294,
         "[SPARK-52587][SHELL] spark-shell 2.13 support `-i` `-I` parameter",
         "closed",
         "2025-06-27T02:59:16.000Z",
         "cxzl25",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177513597,
         51288,
         "[SPARK-52568][BUILD][3.5] Fix `exec-maven-plugin` version used by `dev/test-dependencies.sh`",
         "closed",
         "2025-06-27T00:55:29.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3179171851,
         51295,
         "Fix-AQE-OOM",
         "open",
         "2025-06-26T13:39:02.000Z",
         "zhixingheyi-tian",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177990162,
         51291,
         "[SPARK-52584][BUILD] Make build script to support preview releases in finalize step",
         "closed",
         "2025-06-26T06:49:27.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177923163,
         51290,
         "[SPARK-50686][SQL] Hash to sort aggregation fallback - memory usage optimization",
         "open",
         "2025-06-26T06:20:07.000Z",
         "akupchinskiy",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3177160576,
         51286,
         "[SPARK-52579][PYTHON] Set periodical traceback dump for Python workers",
         "closed",
         "2025-06-26T03:50:55.000Z",
         "ueshin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3161652170,
         51226,
         "[SPARK-52534][ML][CONNECT] Make MLCache and MLHandler thread-safe",
         "closed",
         "2025-06-26T03:01:29.000Z",
         "WeichenXu123",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172685460,
         51273,
         "[SPARK-52568][BUILD] Fix `exec-maven-plugin` version used by `dev/test-dependencies.sh`",
         "closed",
         "2025-06-26T02:29:15.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3174448831,
         51278,
         "[SPARK-52573][PYTHON][TESTS] Add tests for decimal type",
         "closed",
         "2025-06-26T00:36:30.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3173477267,
         51276,
         "[SPARK-52572][PS] Avoid CAST_INVALID_INPUT of DataFrame.isin in ANSI mode ",
         "closed",
         "2025-06-26T00:26:23.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3174912667,
         51279,
         "[SPARK-52574][SQL][TESTS] Ensure compression codec is correctly applied in Hive tables and dirs",
         "closed",
         "2025-06-25T22:50:14.000Z",
         "wangyum",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3176916529,
         51283,
         "[SDP] [SPARK-52577] Add tests for Declarative Pipelines DatasetManager with Hive catalog",
         "open",
         "2025-06-25T20:46:02.000Z",
         "sryza",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172276576,
         51268,
         "[SPARK-52565] [SQL] Enforce ordinal resolution before other sort order expressions",
         "open",
         "2025-06-25T19:30:01.000Z",
         "mihailoale-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172483289,
         51271,
         "[SPARK-52567][SQL][HIVE][TEST] Refactor Hive_2_1_DDLSuite",
         "closed",
         "2025-06-25T17:34:42.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3159409972,
         51223,
         "[SPARK-52533] Support enabling only driver profiler",
         "closed",
         "2025-06-25T17:25:23.000Z",
         "wForget",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172335808,
         51269,
         "[SPARK-37467][SQL] Consolidate subexpression elimination code for whole stage and non-whole stage",
         "open",
         "2025-06-25T17:00:42.000Z",
         "Kimahriman",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172377055,
         51270,
         "[SPARK-52569][SQL] Fix the class cast exception in `SecondsOfTimeWithFraction`",
         "closed",
         "2025-06-25T13:41:38.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3174116201,
         51277,
         "[PYTHON][MINOR] Decrease default `arrowMaxBytesPerBatch` for arrow-optimized UDF",
         "closed",
         "2025-06-25T07:29:07.000Z",
         "asl3",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170504750,
         51263,
         "[SPARK-52339][SQL][FOLLOWUP] Sort paths in InMemoryFileIndex#equal only when size matches",
         "closed",
         "2025-06-25T02:15:33.000Z",
         "yaooqinn",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170126405,
         51260,
         "[SPARK-52562][INFRA] Automatically create the base of release notes and push",
         "closed",
         "2025-06-24T23:42:30.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3171648927,
         51266,
         "[SPARK-52547][INFRA][FOLLOW-UP] Check RELEASE_VERSION and SPARK_RC_COUNT for dryruns",
         "closed",
         "2025-06-24T23:26:36.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169677362,
         51254,
         "[SPARK-52557][PS] Avoid CAST_INVALID_INPUT of to_numeric(errors='coerce') in ANSI mode",
         "closed",
         "2025-06-24T21:28:09.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172492030,
         51272,
         "[SPARK-37466][SQL] Support subexpression elimination in higher order functions",
         "open",
         "2025-06-24T20:23:21.000Z",
         "Kimahriman",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170318376,
         51261,
         "Revert \"[SPARK-50849][CONNECT] Add example project to demonstrate Spark Connect Server Libraries\"",
         "closed",
         "2025-06-24T16:28:43.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3167269028,
         51246,
         "[SPARK-52548][CORE][TESTS] Add a test case for when shuffle manager is overridden by a SparkPlugin",
         "closed",
         "2025-06-24T16:25:13.000Z",
         "zhztheplayer",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3172233702,
         51267,
         "[SPARK-50603][SQL] Respect user-provided basePath for streaming file source reads without glob",
         "open",
         "2025-06-24T14:30:48.000Z",
         "Kimahriman",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3170086199,
         51258,
         "[SPARK-52470][ML][PYTHON][FOLLOW-UP] Further fix GRPC import",
         "closed",
         "2025-06-24T07:53:50.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3168409961,
         51248,
         "[SPARK-52460][SQL][FOLLOWUP] Fix names and test ranges of TIME values",
         "closed",
         "2025-06-24T07:06:15.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169672461,
         51253,
         "[SPARK-52563][PS] Fix var naming bug in _assert_pandas_almost_equal",
         "open",
         "2025-06-24T06:32:05.000Z",
         "petern48",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169907463,
         51256,
         "[SPARK-52339][SQL][3.5] Fix comparison of `InMemoryFileIndex` instances",
         "closed",
         "2025-06-24T06:11:19.000Z",
         "bersprockets",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169729266,
         51255,
         "[SPARK-52553][SS] Fix NumberFormatException when reading v1 changelog",
         "closed",
         "2025-06-24T04:34:00.000Z",
         "micheal-o",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3166050073,
         51243,
         "[SPARK-52546][SQL] check sparkContext if has stopped when running catch code block in execute(), otherwise, it will return wrong state.",
         "closed",
         "2025-06-24T01:46:49.000Z",
         "xuyu-co",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3162430028,
         51229,
         "[SPARK-52536] Set AsyncProfilerLoader extractionDir to spark local dir",
         "closed",
         "2025-06-24T00:22:13.000Z",
         "wForget",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169648510,
         51252,
         "[SPARK-52554][PS] Avoid multiple roundtrips for config check in Spark Connect",
         "closed",
         "2025-06-24T00:21:09.000Z",
         "ueshin",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3166997826,
         51245,
         "[SPARK-52547][INFRA] Build dry runs against master branch",
         "closed",
         "2025-06-23T23:52:22.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169135135,
         51249,
         "[SPARK-52349][PS] Enable boolean division tests with ANSI enabled",
         "closed",
         "2025-06-23T20:52:05.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3169315157,
         51250,
         "Test Apache ORC 1.8.10 RC0",
         "closed",
         "2025-06-23T20:09:02.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3163476334,
         51232,
         "[SPARK-52540][SQL] Make TIMESTAMP_NTZ from DATE and TIME",
         "closed",
         "2025-06-23T16:36:15.000Z",
         "MaxGekk",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164131013,
         51235,
         "[SPARK-52544][SQL] Allow configuring Json datasource string length limit through SQLConf",
         "open",
         "2025-06-23T08:53:21.000Z",
         "tianhanhu",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3163211460,
         51231,
         "[SPARK-52538][SQL] Add new method to check if the value is fully extractable",
         "closed",
         "2025-06-23T07:17:14.000Z",
         "vladimirg-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3166656562,
         51244,
         "[SPARK-52422][BUILD][FOLLOW-UP] Pin pandas as 2.2.3 for release build",
         "closed",
         "2025-06-23T06:47:44.000Z",
         "HyukjinKwon",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3157477307,
         51216,
         "[SPARK-52531][SQL] `OuterReference` in subquery aggregate is incorrectly tied to outer query aggregate",
         "closed",
         "2025-06-23T03:12:06.000Z",
         "mihailotim-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3159459112,
         51224,
         "[SPARK-52532][SQL][TESTS] Add tests for hidden or main output prioritization during attribute name conflict",
         "closed",
         "2025-06-23T02:54:31.000Z",
         "vladimirg-db",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164912210,
         51241,
         "[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test",
         "open",
         "2025-06-23T02:45:15.000Z",
         "ikshitiz",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3158723263,
         51222,
         "[SPARK-52530][SQL][TESTS] Move `SimpleTestOptimizer` to test source directory",
         "closed",
         "2025-06-23T02:32:30.000Z",
         "LuciferYang",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3158254496,
         51219,
         " [SPARK-52528][PS] Enable divide-by-zero for numeric mod with ANSI enabled",
         "closed",
         "2025-06-23T02:24:46.000Z",
         "xinrong-meng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164902661,
         51240,
         "[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test",
         "open",
         "2025-06-21T08:19:17.000Z",
         "ikshitiz",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164886105,
         51237,
         "[SPARK-52401][SQL] Fix DataFrame.collect() cache invalidation after saveAsTable append; add regression test",
         "closed",
         "2025-06-21T08:19:13.000Z",
         "ikshitiz",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3164896683,
         51238,
         "Initial commit",
         "open",
         "2025-06-21T08:09:41.000Z",
         "Raghavdodla",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3162243699,
         51228,
         "[SPARK-52537][CORE] Print stacktrace on creating temp dir failure",
         "closed",
         "2025-06-20T18:08:31.000Z",
         "pan3793",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3158684960,
         51221,
         "[Test]",
         "open",
         "2025-06-19T14:40:57.000Z",
         "WeichenXu123",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3158657228,
         51220,
         "[SPARK-52470][TESTS][FOLLOWUP] Fix test failure caused by import connect in pure classic testing envs",
         "closed",
         "2025-06-19T02:43:03.000Z",
         "zhengruifeng",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3157520210,
         51217,
         "[SPARK-52527][BUILD] Upgrade `junit` to 5.13.1",
         "closed",
         "2025-06-19T02:20:09.000Z",
         "dongjoon-hyun",
         "2025-07-03T13:44:46.381Z"
        ],
        [
         3157608084,
         51218,
         "Feature/spark 44647 backport 3.5.6",
         "closed",
         "2025-06-18T17:22:11.000Z",
         "IgorBerman",
         "2025-07-03T13:44:46.381Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "number",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "updated_at",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "user_login",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingest_ts",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.read.table(\"github_issues_bronze\").orderBy(col(\"updated_at\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae87d5d4-1069-4d60-801d-ee64a140811a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count validation passed: 150\n"
     ]
    }
   ],
   "source": [
    "expected_count = len(raw_data)\n",
    "actual_count = df_filtered.count()\n",
    "\n",
    "assert expected_count == actual_count, f\"Mismatch! Expected: {expected_count}, Got: {actual_count}\"\n",
    "print(f\"Row count validation passed: {expected_count}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "API_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}